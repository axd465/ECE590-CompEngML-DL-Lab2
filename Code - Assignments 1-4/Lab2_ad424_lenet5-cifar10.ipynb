{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 590 - Lab2 - LeNet5 Cifar 10 - Anthony DiSpirito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Info\n",
    "* **Name: Anthony DiSpirito**\n",
    "* **NetID: ad424**\n",
    "* **Class: ECE 590 - Comp Eng ML and DL**\n",
    "* **Title: Lab2 - LeNet5 Cifar10**\n",
    "* **Date: 10/2/19**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LeNet5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# You cannot change this line.\n",
    "from tools.dataloader import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5 Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Assignment 2(a)\n",
    "Build the LeNet-5 model by following table 1 or figure 1.\n",
    "\n",
    "You can also insert batch normalization and leave the LeNet-5 \n",
    "with batch normalization here for assignment 3(c).\n",
    "\"\"\"\n",
    "# Create the neural network module: LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        FUNCTIONS USED IN THIS SECTION:\n",
    "        -----------------------------------------\n",
    "        Conv2d Function takes form:\n",
    "        \n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        -----------------------------------------\n",
    "        BatchNorm2d Function takes the form:\n",
    "        \n",
    "        torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1,\n",
    "                             affine=True, track_running_stats=True)\n",
    "        -----------------------------------------\n",
    "        Linear Function:\n",
    "        torch.nn.Linear(in_features, out_features, bias=True)\n",
    "        '''\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros')\n",
    "        self.bn_conv1 = nn.BatchNorm2d(6, eps=1e-05,momentum=0.1, \n",
    "                                       affine=True, track_running_stats=True)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding=0, dilation=1,\n",
    "                               groups=1, bias=True, padding_mode='zeros')\n",
    "        self.bn_conv2 = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1,\n",
    "                                       affine=True, track_running_stats=True)\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(16*(5**2), 120, bias = True)\n",
    "        self.fc2 = nn.Linear(120, 84, bias = True)     \n",
    "        self.fc3 = nn.Linear(84, 10, bias = True)\n",
    "        return\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First Convolutional Layer (ReLu activation)\n",
    "        out = F.relu(self.bn_conv1(self.conv1(x)))\n",
    "        # First Pooling Layer (2x2 strides and pooling size)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        # Second Convolutional Layer (ReLu activation)\n",
    "        out = F.relu(self.bn_conv2(self.conv2(out)))\n",
    "        # Second Pooling Layer (2x2 strides and pooling size)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        # Reshapes \"out\" so we can input into Fully Connected Layer\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # First Fully Connected Layer (ReLu activation)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        # Second Fully Connected Layer (ReLu activation)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        # Third Fully Connected Layer (Softmax activation)\n",
    "        out = self.fc3(out)#F.softmax(self.fc3(out), dim=0)\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparameter optimization in assignment 4(a), 4(b) can be \n",
    "conducted here.\n",
    "Be sure to leave only your best hyperparameter combination\n",
    "here and comment the original hyperparameter settings.\n",
    "\"\"\"\n",
    "\n",
    "# Setting some hyperparameters\n",
    "TRAIN_BATCH_SIZE = 64#128\n",
    "VAL_BATCH_SIZE = 50#100\n",
    "INITIAL_LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "REG = 1e-4\n",
    "EPOCHS = 100 #30\n",
    "DATAROOT = \"./data\"\n",
    "CHECKPOINT_PATH = \"./saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 2(b)\n",
    "Write functions to load dataset and preprocess the incoming data. \n",
    "We recommend that the preprocess scheme \\textbf{must} include \n",
    "normalize, standardization, batch shuffling to make sure the training \n",
    "process goes smoothly. \n",
    "The preprocess scheme may also contain some data augmentation methods \n",
    "(e.g., random crop, random flip, etc.). \n",
    "\n",
    "Reference value for mean/std:\n",
    "\n",
    "mean(RGB-format): (0.4914, 0.4822, 0.4465)\n",
    "std(RGB-format): (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "\n",
    "NOTE: Considering this process has strong corrlelation with assignment 3(b), \n",
    "please leave the data preprocessing method which can achieve the highest \n",
    "validation accuracy here. You can include your original data augmentation\n",
    "method as comments and denotes the accuracy difference between these two \n",
    "methods.\n",
    "\"\"\"\n",
    "# Specify preprocessing function.\n",
    "# Reference mean/std value\n",
    "mean_RGB = (0.4914, 0.4822, 0.4465)\n",
    "std_RGB = (0.2023, 0.1994, 0.2010)\n",
    "input_img_size = (32,32)\n",
    "percent_crop = 0.80 # 80 percent left after crop\n",
    "data_augment_list = [#transforms.RandomResizedCrop(size = input_img_size, scale=(percent_crop, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "                     transforms.RandomVerticalFlip(p = 0.10),\n",
    "                     transforms.RandomHorizontalFlip(p = 0.15),\n",
    "                     transforms.RandomApply([transforms.RandomCrop(size = input_img_size, padding=4, pad_if_needed=False, fill=0, padding_mode='constant')], p = 0.15),\n",
    "                     transforms.RandomApply([transforms.RandomAffine(degrees = 45, translate=(0.15,0.15), scale=None, shear=None, resample=False, fillcolor=0)], p = 0.20),\n",
    "                     transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05)], p = 0.15)]\n",
    "transform_train = transforms.Compose([transforms.Resize(input_img_size),\n",
    "                                      transforms.RandomOrder(data_augment_list),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.RandomErasing(p=0.10, scale=(0.01, 0.15), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "                                      transforms.Normalize(mean_RGB, std_RGB)])\n",
    "transform_val = transforms.Compose([transforms.Resize(input_img_size),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean_RGB, std_RGB)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\cifar10_trainval.tar.gz\n",
      "Extracting ./data\\cifar10_trainval.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./data\\cifar10_trainval.tar.gz\n",
      "Extracting ./data\\cifar10_trainval.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Call the dataset Loader\n",
    "num_threads = 16\n",
    "trainset = CIFAR10(root=DATAROOT, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=num_threads//2)\n",
    "valset = CIFAR10(root=DATAROOT, train=False, download=True, transform=transform_val)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=num_threads//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on GPU...\n"
     ]
    }
   ],
   "source": [
    "# Specify the device for computation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = LeNet5()\n",
    "net = net.to(device)\n",
    "if device =='cuda':\n",
    "    print(\"Train on GPU...\")\n",
    "else:\n",
    "    print(\"Train on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from scratch ...\n",
      "Starting from learning rate 0.010000:\n"
     ]
    }
   ],
   "source": [
    "# FLAG for loading the pretrained model\n",
    "TRAIN_FROM_SCRATCH = True\n",
    "# Code for loading checkpoint and recover epoch id.\n",
    "CKPT_PATH = \"./saved_model/model.h5\"\n",
    "def get_checkpoint(ckpt_path):\n",
    "    try:\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return ckpt\n",
    "\n",
    "ckpt = get_checkpoint(CKPT_PATH)\n",
    "if ckpt is None or TRAIN_FROM_SCRATCH:\n",
    "    if not TRAIN_FROM_SCRATCH:\n",
    "        print(\"Checkpoint not found.\")\n",
    "    print(\"Training from scratch ...\")\n",
    "    start_epoch = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "else:\n",
    "    print(\"Successfully loaded checkpoint: %s\" %CKPT_PATH)\n",
    "    net.load_state_dict(ckpt['net'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    current_learning_rate = ckpt['lr']\n",
    "    print(\"Starting from epoch %d \" %start_epoch)\n",
    "\n",
    "print(\"Starting from learning rate %f:\" %current_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 2(c)\n",
    "In the targeted classification task, we use cross entropy loss with L2 \n",
    "regularization as the learning object.\n",
    "You need to formulate the cross-entropy loss function in PyTorch.\n",
    "You should also specify a PyTorch Optimizer to optimize this loss function.\n",
    "We recommend you to use the SGD-momentum with an initial learning rate 0.01 \n",
    "and momentum 0.9 as a start.\n",
    "\"\"\"\n",
    "# Create loss function and specify regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Add optimizer\n",
    "optimizer = optim.SGD(net.parameters(), INITIAL_LR, MOMENTUM, weight_decay=REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-30 21:46:25.614295\n",
      "Epoch 0:\n",
      "704\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 16, 10, 10])\n",
      "torch.Size([64, 16, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8cbb9955ec2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Generate output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# Now backward loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-34a677b05e73>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Second Convolutional Layer (ReLu activation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_conv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# Second Pooling Layer (2x2 strides and pooling size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 340\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assignment 3(a)\n",
    "Start the training process over the whole CIFAR-10 training dataset. \n",
    "For sanity check, you are required to report the initial loss value at \n",
    "the beginning of the training process and briefly justify this value. \n",
    "Run the training process for \\textbf{a maximum of 30} epochs and you \n",
    "should be able to reach around \\textbf{65\\%} accuracy on the validation \n",
    "dataset.\n",
    "\"\"\"\n",
    "# Start the training/validation process\n",
    "# The process should take about 5 minutes on a GTX 1070-Ti\n",
    "# if the code is written efficiently.\n",
    "global_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for i in range(start_epoch, EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    # Switch to train mode\n",
    "    net.train()\n",
    "    print(\"Epoch %d:\" %i)\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    # Train the training dataset for 1 epoch.\n",
    "    print(len(trainloader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        # Copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Generate output\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # Now backward loss\n",
    "        loss.backward()\n",
    "        # Apply gradient\n",
    "        optimizer.step()\n",
    "        # Calculate predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Calculate accuracy\n",
    "        total_examples += targets.size(0)\n",
    "        correct_examples += predicted.eq(targets.data).sum().item()\n",
    "        train_loss += loss.data.item()\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 100 == 0:\n",
    "            avg_loss = train_loss / (batch_idx + 1)\n",
    "        pass\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f %%\" %(avg_loss, avg_acc*100))\n",
    "    print(datetime.datetime.now())\n",
    "    # Validate on the validation dataset\n",
    "    print(\"Validation...\")\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    # Disable gradient during validation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            # Copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Generate output from the DNN.\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Calculate predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Calculate accuracy\n",
    "            total_examples += targets.size(0)\n",
    "            correct_examples += predicted.eq(targets.data).sum().item()\n",
    "            val_loss += loss.data.item()\n",
    "\n",
    "    avg_loss = val_loss / len(valloader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Validation loss: %.4f, Validation accuracy: %.4f %%\" %(avg_loss, avg_acc*100))\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Assignment 4(b)\n",
    "    Learning rate is an important hyperparameter to tune. Specify a \n",
    "    learning rate decay policy and apply it in your training process. \n",
    "    Briefly describe its impact on the learning curveduring your \n",
    "    training process.    \n",
    "    Reference learning rate schedule: \n",
    "    decay 0.98 for every 2 epochs. You may tune this parameter but \n",
    "    minimal gain will be achieved.\n",
    "    Assignment 4(c)\n",
    "    As we can see from above, hyperparameter optimization is critical \n",
    "    to obtain a good performance of DNN models. Try to fine-tune the \n",
    "    model to over 70% accuracy. You may also increase the number of \n",
    "    epochs to up to 100 during the process. Briefly describe what you \n",
    "    have tried to improve the performance of the LeNet-5 model.\n",
    "    \"\"\"\n",
    "    DECAY_EPOCHS = 2\n",
    "    DECAY = 0.98#0.98\n",
    "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
    "        current_learning_rate = INITIAL_LR*(DECAY**i)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            # Assign the learning rate parameter\n",
    "            param_group['lr'] = current_learning_rate\n",
    "        print(\"Current learning rate has decayed to %f\" %(current_learning_rate*(DECAY**i)))\n",
    "    \n",
    "    # Save for checkpoint\n",
    "    if avg_acc > best_val_acc:\n",
    "        best_val_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_PATH):\n",
    "            os.makedirs(CHECKPOINT_PATH)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'net': net.state_dict(),\n",
    "                 'epoch': i,\n",
    "                 'lr': current_learning_rate}\n",
    "        torch.save(state, os.path.join(CHECKPOINT_PATH, 'model.h5'))\n",
    "\n",
    "print(\"Optimization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
